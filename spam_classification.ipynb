{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# loading libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "data = pd.read_csv('spam_data.csv', header=None, names=['message_class', 'message'])\n",
    "message_class = {'spam':0, 'ham':1}\n",
    "\n",
    "data['message_class'] = data['message_class'].map(message_class) \n",
    "\n",
    "text_data = data['message']\n",
    "target_data = data['message_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "def clean_data(text_data):\n",
    "    #Converting to lowercase\n",
    "    text_data = [x.lower() for x in text_data]\n",
    "    # Removing numbers\n",
    "    digits = '0123456789'\n",
    "    text_data = [''.join(c for c in x if c not in digits) for x in text_data]\n",
    "    # Removing punctuation\n",
    "    text_data = [''.join(c for c in x if c not in string.punctuation)\n",
    "                 for x in text_data]\n",
    "    # Trimming extra whitespace\n",
    "    text_data = [' '.join(x.split()) for x in text_data]\n",
    "    return text_data\n",
    "text_data = clean_data(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lemmatizing tokenized texts\n",
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "def tokenizer(text_data):\n",
    "    spacy_data = en_nlp(text_data)\n",
    "    lemmatized_data = [token.lemma_ for token in spacy_data]\n",
    "    return lemmatized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# vectorizing texts for model training\n",
    "min_word_frequency = 10\n",
    "max_features = 1000\n",
    "vocab_processor = TfidfVectorizer(min_df=min_word_frequency, max_features=max_features, \n",
    "                             tokenizer=tokenizer, stop_words='english')\n",
    "processed_data = vocab_processor.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting into train and test sets\n",
    "texts_train, texts_test, target_train, target_test = train_test_split (processed_data, target_data,\n",
    "                                                                       test_size=0.20, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score of LR is [0.97309417 0.96860987 0.96860987 0.9573991  0.96412556 0.97533632\n",
      " 0.94843049 0.96412556 0.97085202 0.94831461]\n",
      "mean: 0.9638897566382829\n",
      "standard deviation: 0.009124642219438373\n",
      "validation score of smv is [0.88789238 0.867713   0.88340807 0.83856502 0.867713   0.89461883\n",
      " 0.84977578 0.87892377 0.87219731 0.84494382]\n",
      "mean: 0.8685750995112611\n",
      "standard deviation: 0.017904212999400874\n",
      "validation score of KNN is [0.93497758 0.92600897 0.94618834 0.92152466 0.91928251 0.93721973\n",
      " 0.89686099 0.91928251 0.94394619 0.88988764]\n",
      "mean: 0.9235179120270065\n",
      "standard deviation: 0.01771431369080569\n",
      "validation score of DCtree is [0.95964126 0.95964126 0.95067265 0.96636771 0.9573991  0.9529148\n",
      " 0.93721973 0.96636771 0.95067265 0.94157303]\n",
      "mean: 0.9542469894694412\n",
      "standard deviation: 0.009164274113505136\n",
      "validation score of RmForest is [0.97533632 0.97309417 0.97309417 0.97982063 0.96188341 0.97085202\n",
      " 0.96188341 0.97757848 0.97085202 0.94831461]\n",
      "mean: 0.9692709225575653\n",
      "standard deviation: 0.008942331247497288\n"
     ]
    }
   ],
   "source": [
    "# model selection\n",
    "models = []\n",
    "names = []\n",
    "\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('smv', SVC()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('DCtree', DecisionTreeClassifier()))\n",
    "models.append(('RmForest', RandomForestClassifier()))  \n",
    "\n",
    "for name, model in models:\n",
    "    classifier = model\n",
    "    classifier.fit(texts_train, target_train)\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    val_scores = cross_val_score(classifier, texts_train, target_train, cv=kfold)\n",
    "    msg = \"validation score of {} is {}\".format(name, val_scores)\n",
    "    print(msg)\n",
    "    print('mean:', val_scores.mean())\n",
    "    print('standard deviation:', val_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Confusion matrix:\n",
      "[[134  27]\n",
      " [  2 952]]\n",
      "f1 score: 0.98\n",
      "AUC: 0.989\n",
      "RMF\n",
      "Confusion matrix:\n",
      "[[140  21]\n",
      " [ 13 941]]\n",
      "f1 score: 0.98\n",
      "AUC: 0.983\n"
     ]
    }
   ],
   "source": [
    "selected_models = []\n",
    "selected_models.append(('LR', LogisticRegression()))\n",
    "selected_models.append(('RmForest', RandomForestClassifier()))\n",
    "msg = 'Logistic Regression'\n",
    "for name, selected_model in selected_models:\n",
    "    print (msg)\n",
    "    classifier = selected_model\n",
    "    classifier.fit(texts_train, target_train)\n",
    "    pred_ = classifier.predict(texts_test)\n",
    "    confusion = confusion_matrix(target_test, pred_)\n",
    "    print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "    F1Score = f1_score(target_test, pred_)\n",
    "    print(\"f1 score: {:.2f}\".format(F1Score))\n",
    "    clf_auc = roc_auc_score(target_test, classifier.predict_proba(texts_test)[:, 1]) \n",
    "    print(\"AUC: {:.3f}\".format(clf_auc))\n",
    "    msg = 'RMF'  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
